{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud Data Pipeline for International Bank for Reconstruction and Development(IBRD)\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "The International Bank for Reconstruction and Development, wants to move their processes and data pipeline onto the cloud. Their data resides in S3, in a directory of CSV on the transcation history of the loans. \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Clean and Save the Data\n",
    "* Step 4: Define the Data Model\n",
    "* Step 5: Run ETL to Model the Data\n",
    "* Step 6: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "* Project Description\n",
    "\n",
    "In this project, we will build an ETL pipeline that extracts data from S3, processes and clean them using Spark, and loads the data back into S3 as a set of dimensional tables in csv format. Then, create cluster with redshift and load data into redshift. This will allow our analytics team to continue finding insights of our loan users.\n",
    "\n",
    "* Tool\n",
    "\n",
    " In this porject, we will use AWS S3, Redshift, Spark, Python\n",
    " \n",
    "#### Describe and Gather Data \n",
    "The data is coming from World Bank and you can download it from below page:\n",
    "\n",
    "https://finances.worldbank.org/Loans-and-Credits/IBRD-Statement-Of-Loans-Historical-Data/zucq-nrc3\n",
    "It is around 300mb and below is the data layout of the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### End of PeriodEnd of Period Date \n",
    "represents the date as of which balances are shown in the report.\n",
    "##### Loan Number\n",
    "For IBRD loans and IDA credits or grants a loan number consists of the organization prefix (IBRD/IDA) and a five-character label that uniquely identifies the loan within the organization. In IDA, all grant labels start with the letter ‘H’.\n",
    "#####  RegionCountry \n",
    "lending is grouped into regions based on the current World Bank administrative (rather than geographic) region where project implementation takes place. The Other Region is used for loans to the IFC.\n",
    "##### Country Code\n",
    "Country Code according to the World Bank country list. Might be different from the ISO country code.\n",
    "##### Country\n",
    "Country to which loan has been issued. Loans to the IFC are included under the country “World”.\n",
    "##### Borrower\n",
    "The representative of the borrower to which the Bank loan is made.\n",
    "##### Guarantor Country \n",
    "CodeCountry Code of the Guarantor according to the World Bank country list. Might be different from the ISO country code.\n",
    "##### Guarantor\n",
    "The Guarantor guarantees repayment to the Bank if the borrower does not repay.\n",
    "##### Loan \n",
    "TypeA type of loan/loan instrument for which distinctive accounting and/or other actions need to be performed. See Data Dictionary attached in the About section or Data Dictionary dataset available from the list of all datasets for details.\n",
    "##### Loan StatusStatus of the loan. \n",
    "See Data Dictionary attached in the About section or Data Dictionary dataset available from the list of all datasets for status descriptions.\n",
    "##### Interest Rate\n",
    "Current Interest rate or service charge applied to loan. For loans that could have more than one interest rate (e.g. FSL or SCL fixed rate loans), the interest rate is shown as “0”.\n",
    "##### Currency of Commitment\n",
    "The currency in which a borrower’s loan, credit, grant or trust fund is denominated.\n",
    "##### Project \n",
    "IDA Bank project is referenced by a project ID (Pxxxxxxx). More than one loan or credit may be associated with one Project ID.\n",
    "##### Project Name \n",
    "Short descriptive project name.\n",
    "##### Original Principal Amount\n",
    "The original US dollar amount of the loan that is committed and approved.\n",
    "##### Cancelled Amount\n",
    "The portion of the undisbursed balance which has been cancelled (i.e. no longer available for future disbursement). Cancellations include terminations (where approved loan agreements were never signed).\n",
    "##### Undisbursed Amount\n",
    "The amount of a loan commitment that is still available to be drawn down. These currency amounts have been converted to US dollars at the exchange rates applicable at the end of period date.\n",
    "##### Disbursed Amount\n",
    "The amount that has been disbursed from a loan commitment in equivalent US dollars, calculated at the exchange rate on the value date of the individual disbursements.\n",
    "##### Repaid to IBRD\n",
    "Total principal amounts paid or prepaid to IBRD in US dollars, calculated at the exchange rate on the value date of the individual repayments.\n",
    "##### Due to IBRD\n",
    "Where the exchange adjustment is shown separately, this is the amount disbursed and outstanding expressed as a stock of debt in historical US Dollars. Where the exchange adjustment is not shown separately, this is the amount due and outstanding as of th\n",
    "##### Exchange Adjustment\n",
    "The increase (decrease) in value of disbursed and outstanding amount due to exchange rate fluctuations. This amount added to “Due to IBRD” yields “Borrower’s Obligation; includes exchange adjustments on the amounts Due to 3rd parties.\n",
    "##### Borrower's Obligation\n",
    "The Borrower Obligation is the outstanding balance for the loan as of the end of period date in US dollars equivalent. The Borrower's Obligation includes the amounts outstanding Due to 3rd parties.\n",
    "##### Sold 3rd Party\n",
    "Portion of loan sold to a third party.\n",
    "Repaid 3rd PartyAmount repaid to a third party.\n",
    "##### Due 3rd Party\n",
    "Amount due to a third party.\n",
    "Loans HeldThe sum of the disbursed and outstanding amounts (net of repayments, i.e. Due to IBRD/IDA) plus undisbursed available amounts expressed in historical US Dollars.\n",
    "##### First Repayment Date\n",
    "The date on which principal repayment starts.\n",
    "##### Last Repayment Date\n",
    "The date specified in the loan/credit agreement (amended for any partial prepayments) on which the last principal installment must be repaid by the Borrower.\n",
    "##### Agreement Signing Date\n",
    "The date the borrower and the Bank sign the loan agreement.\n",
    "##### Board Approval Date\n",
    "The date the World Bank approves the loan.\n",
    "##### Effective Date (Most Recent)\n",
    "The date on which a legal agreement becomes effective, or is expected to become effective.\n",
    "##### Closed Date (Most Recent)\n",
    "The date specified in the legal agreement (or extension) after which the Bank may, by notice to the borrower, terminate the right to make withdrawals from the loan account.\n",
    "##### Last Disbursement Date\n",
    "The date on which the last disbursement was made (prior to the end of period date)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all modules and setup here\n",
    "# Loading all library\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.sql.types import StringType\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Window\n",
    "import boto3\n",
    "import time\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "# Change padans parameter to adjust visliazation\n",
    "pd.set_option('max_colwidth', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "# Load in aws credential\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "KEY = config.get('AWS','KEY')\n",
    "SECRET = config.get('AWS','SECRET')\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['KEY']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['SECRET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that creates spark session\n",
    "def create_spark_session():\n",
    "    \"\"\"\n",
    "    This function is used to create a spark session to work in\n",
    "    \"\"\"\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "    return spark\n",
    "# Create spark session\n",
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from AWS s3\n",
    "df_spark = spark.read.csv(\"s3a://udacity-leejohn/loan/ibrd-statement-of-loans-historical-data.csv\", header=True)\n",
    "# Function that will uppercase everything in the dataframe\n",
    "fields = df_spark.schema.fields\n",
    "stringFields = filter(lambda f: isinstance(f.dataType, StringType), fields)\n",
    "nonStringFields = map(lambda f: col(f.name), filter(lambda f: not isinstance(f.dataType, StringType), fields))\n",
    "stringFieldsTransformed = map(lambda f: upper(col(f.name)), stringFields) \n",
    "allFields = [*stringFieldsTransformed, *nonStringFields]\n",
    "df_new = df_spark.select(allFields)\n",
    "# Rename the column name\n",
    "# Get old column names \n",
    "oldColumns = df_new.schema.names\n",
    "# Setup new column names\n",
    "newColumns  = ['End_of_Period', 'Loan_Number', 'Region', 'Country_Code', 'Country','Borrower','Guarantor_Country_Code','Guarantor','Loan_Type','Loan_Status','Interest_Rate','Currency_of_Commitment','Project_ID','Project_Name','Original_Principal_Amount','Cancelled_Amount','Undisbursed_Amount','Disbursed_Amount','Repaid_to_IBRD','Due_to_IBRD','Exchange_Adjustment','Borrowers_Obligation','Sold_3rd_Party','Repaid_3rd_Party','Due_3rd_Party','Loans_Held','First_Repayment_Date','Last_Repayment_Date','Agreement_Signing_Date','Board_Approval_Date','Effective_Date_Most_Recent','Closed_Date_Most_Recent','Last_Disbursement_Date']\n",
    "# Rename the dataframe\n",
    "df = reduce(lambda df_spark, idx: df_spark.withColumnRenamed(oldColumns[idx], newColumns[idx]), range(len(oldColumns)), df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rows in data\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>End_of_Period</th>\n",
       "      <th>Loan_Number</th>\n",
       "      <th>Region</th>\n",
       "      <th>Country_Code</th>\n",
       "      <th>Country</th>\n",
       "      <th>Borrower</th>\n",
       "      <th>Guarantor_Country_Code</th>\n",
       "      <th>Guarantor</th>\n",
       "      <th>Loan_Type</th>\n",
       "      <th>Loan_Status</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Currency_of_Commitment</th>\n",
       "      <th>Project_ID</th>\n",
       "      <th>Project_Name</th>\n",
       "      <th>Original_Principal_Amount</th>\n",
       "      <th>Cancelled_Amount</th>\n",
       "      <th>Undisbursed_Amount</th>\n",
       "      <th>Disbursed_Amount</th>\n",
       "      <th>Repaid_to_IBRD</th>\n",
       "      <th>Due_to_IBRD</th>\n",
       "      <th>Exchange_Adjustment</th>\n",
       "      <th>Borrowers_Obligation</th>\n",
       "      <th>Sold_3rd_Party</th>\n",
       "      <th>Repaid_3rd_Party</th>\n",
       "      <th>Due_3rd_Party</th>\n",
       "      <th>Loans_Held</th>\n",
       "      <th>First_Repayment_Date</th>\n",
       "      <th>Last_Repayment_Date</th>\n",
       "      <th>Agreement_Signing_Date</th>\n",
       "      <th>Board_Approval_Date</th>\n",
       "      <th>Effective_Date_Most_Recent</th>\n",
       "      <th>Closed_Date_Most_Recent</th>\n",
       "      <th>Last_Disbursement_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>802137</td>\n",
       "      <td>802137</td>\n",
       "      <td>802137</td>\n",
       "      <td>802137</td>\n",
       "      <td>802137</td>\n",
       "      <td>796580</td>\n",
       "      <td>770595</td>\n",
       "      <td>743002</td>\n",
       "      <td>802089</td>\n",
       "      <td>802089</td>\n",
       "      <td>775755</td>\n",
       "      <td>48</td>\n",
       "      <td>770748</td>\n",
       "      <td>603238</td>\n",
       "      <td>802089</td>\n",
       "      <td>802089</td>\n",
       "      <td>802089</td>\n",
       "      <td>802089</td>\n",
       "      <td>802089</td>\n",
       "      <td>802089</td>\n",
       "      <td>802089</td>\n",
       "      <td>802089</td>\n",
       "      <td>802089</td>\n",
       "      <td>802089</td>\n",
       "      <td>802089</td>\n",
       "      <td>802089</td>\n",
       "      <td>798315</td>\n",
       "      <td>798411</td>\n",
       "      <td>792062</td>\n",
       "      <td>802041</td>\n",
       "      <td>797438</td>\n",
       "      <td>801295</td>\n",
       "      <td>450242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6070833333333335</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8000000.0</td>\n",
       "      <td>235.78813540232693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3636810.0200000014</td>\n",
       "      <td>4906399.120624998</td>\n",
       "      <td>7.683324418806152E7</td>\n",
       "      <td>9668568.033589192</td>\n",
       "      <td>7655266.693610078</td>\n",
       "      <td>5.9512477889023624E7</td>\n",
       "      <td>3.98461426406178E7</td>\n",
       "      <td>1.935132263823048E7</td>\n",
       "      <td>-214132.04400157375</td>\n",
       "      <td>1.9138333455590654E7</td>\n",
       "      <td>445558.31082740123</td>\n",
       "      <td>445558.31082740123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7008203155569147E7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.40571428125490533</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29374.007637237624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106784.82174868968</td>\n",
       "      <td>1.4862488000733185E8</td>\n",
       "      <td>4.464619032854254E7</td>\n",
       "      <td>5.437482376824411E7</td>\n",
       "      <td>1.2757727483751363E8</td>\n",
       "      <td>8.82332276180936E7</td>\n",
       "      <td>9.361462870492262E7</td>\n",
       "      <td>9208274.311718144</td>\n",
       "      <td>9.111660210168463E7</td>\n",
       "      <td>3881816.4242969775</td>\n",
       "      <td>3881816.4242969775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1411908294752274E8</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>2011-04-30T00:00:00.000</td>\n",
       "      <td>GFMDR</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>1W</td>\n",
       "      <td>REPAID</td>\n",
       "      <td>#MULTIVALUE</td>\n",
       "      <td>1W</td>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>\\tIFC LOAN</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3636810.02</td>\n",
       "      <td>COAL IAP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>1930-02-15T00:00:00.000</td>\n",
       "      <td>1930-01-15T00:00:00.000</td>\n",
       "      <td>1947-05-09T00:00:00.000</td>\n",
       "      <td>1947-05-09T00:00:00.000</td>\n",
       "      <td>1947-06-09T00:00:00.000</td>\n",
       "      <td>1947-12-31T00:00:00.000</td>\n",
       "      <td>1983-10-11T00:00:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>KA BANKA D.D.\"</td>\n",
       "      <td>IBRDS0200</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZIMBABWE</td>\n",
       "      <td>ZONA FRANCA INDUST. Y COMERC.</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZIMBABWE</td>\n",
       "      <td>SNGL CRNCY</td>\n",
       "      <td>TERMINATED</td>\n",
       "      <td>9.97</td>\n",
       "      <td>0</td>\n",
       "      <td>P999186</td>\n",
       "      <td>ZOUXIAN THERMAL POWE</td>\n",
       "      <td>99963871.4</td>\n",
       "      <td>9999937.5</td>\n",
       "      <td>9999937.5</td>\n",
       "      <td>99999972.31</td>\n",
       "      <td>99999999.99</td>\n",
       "      <td>99990000</td>\n",
       "      <td>9998114.98</td>\n",
       "      <td>999975000</td>\n",
       "      <td>997000</td>\n",
       "      <td>997000</td>\n",
       "      <td>1997-11-18T00:00:00.000</td>\n",
       "      <td>9999515.72</td>\n",
       "      <td>2049-07-15T00:00:00.000</td>\n",
       "      <td>2061-08-15T00:00:00.000</td>\n",
       "      <td>2019-04-11T00:00:00.000</td>\n",
       "      <td>2019-04-30T00:00:00.000</td>\n",
       "      <td>2020-08-01T00:00:00.000</td>\n",
       "      <td>2033-12-31T00:00:00.000</td>\n",
       "      <td>2019-05-03T00:00:00.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary            End_of_Period Loan_Number      Region Country_Code  \\\n",
       "0   count                   802137      802137      802137       802137   \n",
       "1    mean                     None        None        None         None   \n",
       "2  stddev                     None        None        None         None   \n",
       "3     min  2011-04-30T00:00:00.000       GFMDR      AFRICA           1W   \n",
       "4     max           KA BANKA D.D.\"   IBRDS0200  SOUTH ASIA           ZW   \n",
       "\n",
       "    Country                       Borrower Guarantor_Country_Code Guarantor  \\\n",
       "0    802137                         796580                 770595    743002   \n",
       "1      None             0.6070833333333335                   None      None   \n",
       "2      None            0.40571428125490533                   None      None   \n",
       "3   REPAID                     #MULTIVALUE                     1W   ALBANIA   \n",
       "4  ZIMBABWE  ZONA FRANCA INDUST. Y COMERC.                     ZW  ZIMBABWE   \n",
       "\n",
       "    Loan_Type Loan_Status       Interest_Rate Currency_of_Commitment  \\\n",
       "0      802089      802089              775755                     48   \n",
       "1        None   8000000.0  235.78813540232693                    0.0   \n",
       "2        None         0.0  29374.007637237624                    0.0   \n",
       "3  \\tIFC LOAN   APPROVED                    0                      0   \n",
       "4  SNGL CRNCY  TERMINATED                9.97                      0   \n",
       "\n",
       "           Project_ID          Project_Name Original_Principal_Amount  \\\n",
       "0              770748                603238                    802089   \n",
       "1  3636810.0200000014     4906399.120624998       7.683324418806152E7   \n",
       "2                 0.0    106784.82174868968      1.4862488000733185E8   \n",
       "3          3636810.02              COAL IAP                         0   \n",
       "4             P999186  ZOUXIAN THERMAL POWE                99963871.4   \n",
       "\n",
       "      Cancelled_Amount   Undisbursed_Amount      Disbursed_Amount  \\\n",
       "0               802089               802089                802089   \n",
       "1    9668568.033589192    7655266.693610078  5.9512477889023624E7   \n",
       "2  4.464619032854254E7  5.437482376824411E7  1.2757727483751363E8   \n",
       "3                    0                -0.01                     0   \n",
       "4            9999937.5            9999937.5           99999972.31   \n",
       "\n",
       "       Repaid_to_IBRD          Due_to_IBRD  Exchange_Adjustment  \\\n",
       "0              802089               802089               802089   \n",
       "1  3.98461426406178E7  1.935132263823048E7  -214132.04400157375   \n",
       "2  8.82332276180936E7  9.361462870492262E7    9208274.311718144   \n",
       "3                   0                -0.01                -0.01   \n",
       "4         99999999.99             99990000           9998114.98   \n",
       "\n",
       "   Borrowers_Obligation      Sold_3rd_Party    Repaid_3rd_Party  \\\n",
       "0                802089              802089              802089   \n",
       "1  1.9138333455590654E7  445558.31082740123  445558.31082740123   \n",
       "2   9.111660210168463E7  3881816.4242969775  3881816.4242969775   \n",
       "3                 -0.01                   0                   0   \n",
       "4             999975000              997000              997000   \n",
       "\n",
       "             Due_3rd_Party            Loans_Held     First_Repayment_Date  \\\n",
       "0                   802089                802089                   798315   \n",
       "1                      0.0  2.7008203155569147E7                     None   \n",
       "2                      0.0  1.1411908294752274E8                     None   \n",
       "3                        0                 -0.01  1930-02-15T00:00:00.000   \n",
       "4  1997-11-18T00:00:00.000            9999515.72  2049-07-15T00:00:00.000   \n",
       "\n",
       "       Last_Repayment_Date   Agreement_Signing_Date      Board_Approval_Date  \\\n",
       "0                   798411                   792062                   802041   \n",
       "1                     None                     None                     None   \n",
       "2                     None                     None                     None   \n",
       "3  1930-01-15T00:00:00.000  1947-05-09T00:00:00.000  1947-05-09T00:00:00.000   \n",
       "4  2061-08-15T00:00:00.000  2019-04-11T00:00:00.000  2019-04-30T00:00:00.000   \n",
       "\n",
       "  Effective_Date_Most_Recent  Closed_Date_Most_Recent   Last_Disbursement_Date  \n",
       "0                     797438                   801295                   450242  \n",
       "1                       None                     None                     None  \n",
       "2                       None                     None                     None  \n",
       "3    1947-06-09T00:00:00.000  1947-12-31T00:00:00.000  1983-10-11T00:00:00.000  \n",
       "4    2020-08-01T00:00:00.000  2033-12-31T00:00:00.000  2019-05-03T00:00:00.000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the data\n",
    "df.describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to display the number of null value of each column, before we do any cleaning, you will see null data count for each column with below command\n",
    "df.select(*(sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns)).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Cleaning Steps\n",
    "\n",
    "In this step, we will clean data to remove any null value with different methods. \n",
    "This process will take about 8 min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since below 2 columns have too much null values(average 50% null values) and are not necessary, so we drop them.  \n",
    "df = df.drop('Last_Disbursement_Date')\n",
    "df = df.drop('Currency_of_Commitment')\n",
    "# For these 2 columns, if we look into the raw data,we will see that there are some \"?\", \"@\" in the data, which are some errors come from raw data. \n",
    "# I think this is the error comes from different coding type.\n",
    "# Instead of trying to fix them, we can just drop them.\n",
    "df = df.drop('Borrower')\n",
    "df = df.drop('Project_Name')\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the loan_number to make it 9 digits\n",
    "# From data layout, we can know that loan_number should follow a 9 dights pattern.\n",
    "# Find records that have less than 9 digits Loan_Number, replace them to the correct format\n",
    "df_6 = df.where(length(col(\"Loan_Number\")) == 6).withColumn(\"Loan_Number\", regexp_replace(col(\"Loan_Number\") ,  \"(\\\\w{4})(\\\\d{2})\" , \"$1000$2\" ))\n",
    "df_7 = df.where(length(col(\"Loan_Number\")) == 7).withColumn(\"Loan_Number\", regexp_replace(col(\"Loan_Number\") ,  \"(\\\\w{4})(\\\\d{3})\" , \"$100$2\" ))\n",
    "df_8 = df.where(length(col(\"Loan_Number\")) == 8).withColumn(\"Loan_Number\", regexp_replace(col(\"Loan_Number\") ,  \"(\\\\w{4})(\\\\d{4})\" , \"$10$2\" ))\n",
    "\n",
    "# No records with loan_number that has less than 9 digits\n",
    "df = df.filter(length(col(\"Loan_Number\")) == 9).union(df_6).union(df_7).union(df_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If both Guarantor_Country_Code and Guarantor are empty, then it's hard to say whether they are suppose to be empty(no guarantor)\n",
    "# or they are missing values, so I just drop them.\n",
    "df = df.filter('Guarantor_Country_Code is not NULL or Guarantor is not NULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each loan number, there should be one country code. Run below code, we will find there are 3 records that have the wrong country data, so we drop them. \n",
    "#df.select('Loan_Number','Country_Code').distinct().groupBy('Loan_Number').count().withColumnRenamed('count', 'ccount').filter('count>1').toPandas()\n",
    "#df.where(df.Loan_Number == 'IBRD82610').select('Country').groupBy('Country').count().toPandas()\n",
    "#df.where(df.Loan_Number == 'IBRD82550').select('Country').groupBy('Country').count().toPandas()\n",
    "#df.where(df.Loan_Number == 'IBRD82580').select('Country').groupBy('Country').count().toPandas()\n",
    "df = df.where((df.Loan_Number == 'IBRD82580') & (df.Country != 'CHINA') | (df.Loan_Number != 'IBRD82580'))\n",
    "df = df.where((df.Loan_Number == 'IBRD82550') & (df.Country != 'CHINA') | (df.Loan_Number != 'IBRD82550'))\n",
    "df = df.where((df.Loan_Number == 'IBRD82610') & (df.Country != 'INDIA') | (df.Loan_Number != 'IBRD82610'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all missing value for Project_ID column\n",
    "# Create a dict that key is loan_number and value is project_id\n",
    "x1 = df.filter('Project_ID is not NULL').select('Loan_Number','Project_ID').distinct().toPandas().set_index('Loan_Number')['Project_ID'].to_dict() \n",
    "# Create a pandas dataframe that only has the records that have missing project_id\n",
    "pdf = df.filter('Project_ID is NULL').toPandas()\n",
    "# Loop through the dataframe and replace its missing value with the loan_number\n",
    "for index,row in pdf.iterrows():\n",
    "    att = row.Loan_Number\n",
    "    if att in x1.keys():\n",
    "        row.Project_ID = x1.get(att)\n",
    "# Convert it back to a spark dataframe\n",
    "ddd = spark.createDataFrame(pdf.astype(str)).filter('Project_ID is not NULL').filter('Project_ID != \\'None\\'')\n",
    "# Union it with the good records and get new dataframe\n",
    "df = df.filter('Project_ID is not NULL').union(ddd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all missing value for Guarantor and Guarantor_Country_Code column\n",
    "# Create a dict that key is loan_number and value is a array of country, country_code\n",
    "c1 = df.select('Loan_Number','Country','Country_Code').distinct().toPandas().set_index('Loan_Number').T.to_dict('list')\n",
    "# By exploring data, we find there is one more country in Guarantor, which is united kingdom, we will add it to our dict\n",
    "c1b = df.filter('Guarantor == \\'UNITED KINGDOM\\'').select('Loan_Number').distinct().collect()\n",
    "for i in c1b:\n",
    "    c1[i.Loan_Number] = ['UNITED KINGDOM','GB']\n",
    "# Loop through the dataframe and replace its missing value with the loan_number\n",
    "pdf = df.filter('Guarantor is NULL or Guarantor_Country_Code is NULL').toPandas()\n",
    "for index,row in pdf.iterrows():\n",
    "    att = row.Loan_Number\n",
    "    if att in c1.keys():\n",
    "        row.Guarantor = c1.get(att)[0]\n",
    "        row.Guarantor_Country_Code = c1.get(att)[1]\n",
    "# Convert it back to a spark dataframe\n",
    "ddd = spark.createDataFrame(pdf).filter('Guarantor is not NULL and Guarantor_Country_Code is not NULL')\n",
    "# Union it with the good records and get new dataframe\n",
    "df = df.filter('Guarantor is not NULL and Guarantor_Country_Code is not NULL').union(ddd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 463.7417585849762 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Remove all missing value for Interest_Rate\n",
    "# Since for each loan number, we will find different interest rate. So to handle this case, for rach loan number, I will use mean value of all intertest rate to repalce its nul value. \n",
    "# Create a dict that key is loan_number and value is intertest rate\n",
    "i1 = df.filter('Interest_Rate is not NULL').filter('Interest_Rate != \\'None\\'').select('Loan_Number','Interest_Rate').distinct().toPandas()\n",
    "i1.Interest_Rate = i1.Interest_Rate.astype(np.float16)\n",
    "i1 = i1.groupby('Loan_Number', as_index=True).agg({\"Interest_Rate\": \"mean\"})['Interest_Rate'].to_dict()\n",
    "pdf = df.filter('Interest_Rate is NULL').toPandas()\n",
    "# Loop through the dataframe and replace its missing value with the loan_number\n",
    "for index,row in pdf.iterrows():\n",
    "    att = row.Interest_Rate\n",
    "    if att in c1.keys():\n",
    "        row.Interest_Rate = c1.get(att)\n",
    "# Convert it back to a spark dataframe\n",
    "ddd = spark.createDataFrame(pdf.astype(str)).filter('Interest_Rate is not NULL').filter('Interest_Rate != \\'None\\'')\n",
    "# Union it with the good records and get new dataframe\n",
    "df = df.filter('Interest_Rate is not NULL').union(ddd)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>End_of_Period</th>\n",
       "      <th>Loan_Number</th>\n",
       "      <th>Region</th>\n",
       "      <th>Country_Code</th>\n",
       "      <th>Country</th>\n",
       "      <th>Guarantor_Country_Code</th>\n",
       "      <th>Guarantor</th>\n",
       "      <th>Loan_Type</th>\n",
       "      <th>Loan_Status</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Project_ID</th>\n",
       "      <th>Original_Principal_Amount</th>\n",
       "      <th>Cancelled_Amount</th>\n",
       "      <th>Undisbursed_Amount</th>\n",
       "      <th>Disbursed_Amount</th>\n",
       "      <th>Repaid_to_IBRD</th>\n",
       "      <th>Due_to_IBRD</th>\n",
       "      <th>Exchange_Adjustment</th>\n",
       "      <th>Borrowers_Obligation</th>\n",
       "      <th>Sold_3rd_Party</th>\n",
       "      <th>Repaid_3rd_Party</th>\n",
       "      <th>Due_3rd_Party</th>\n",
       "      <th>Loans_Held</th>\n",
       "      <th>First_Repayment_Date</th>\n",
       "      <th>Last_Repayment_Date</th>\n",
       "      <th>Agreement_Signing_Date</th>\n",
       "      <th>Board_Approval_Date</th>\n",
       "      <th>Effective_Date_Most_Recent</th>\n",
       "      <th>Closed_Date_Most_Recent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>786</td>\n",
       "      <td>699</td>\n",
       "      <td>7885</td>\n",
       "      <td>0</td>\n",
       "      <td>4059</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   End_of_Period  Loan_Number  Region  Country_Code  Country  \\\n",
       "0              0            0       0             0        0   \n",
       "\n",
       "   Guarantor_Country_Code  Guarantor  Loan_Type  Loan_Status  Interest_Rate  \\\n",
       "0                       0          0          0            0              0   \n",
       "\n",
       "   Project_ID  Original_Principal_Amount  Cancelled_Amount  \\\n",
       "0           0                          0                 0   \n",
       "\n",
       "   Undisbursed_Amount  Disbursed_Amount  Repaid_to_IBRD  Due_to_IBRD  \\\n",
       "0                   0                 0               0            0   \n",
       "\n",
       "   Exchange_Adjustment  Borrowers_Obligation  Sold_3rd_Party  \\\n",
       "0                    0                     0               0   \n",
       "\n",
       "   Repaid_3rd_Party  Due_3rd_Party  Loans_Held  First_Repayment_Date  \\\n",
       "0                 0              0           0                   786   \n",
       "\n",
       "   Last_Repayment_Date  Agreement_Signing_Date  Board_Approval_Date  \\\n",
       "0                  699                    7885                    0   \n",
       "\n",
       "   Effective_Date_Most_Recent  Closed_Date_Most_Recent  \n",
       "0                        4059                      430  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is to display the number of null value of each column, before we do any cleaning, you will see null data count for each column with below command\n",
    "df.select(*(sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns)).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After above steps, we wouldn't see any missing value except for the date related columns.\n",
    "For date related columns, since they have more problems, we are not necessarily to remove all missing value. We have another way to deal with them.\n",
    "\n",
    "There are 2 issues with date related columns:\n",
    "1. Missing values\n",
    "2. Having more than one date.\n",
    "For each loan_number, we should only have one unique set of [First_Repayment_Date,Last_Repayment_Date,Agreement_Signing_Date,Board_Approval_Date,Effective_Date_Most_Recent,Closed_Date_Most_Recent],\n",
    "However, we will see there are more than one set.\n",
    "\n",
    "To handle this case, for each date related column, we can find the most frequent date of each loan number and use it as its only date. By doing this, we can find a unique set of date values for each loan number.\n",
    "Therefore, we can create time table directly. Later we will need to create the transaction data, we can ignore the raw data of these date related columns and use loan number to recreate these columns.\n",
    "This will also help us prevent spending time on cleaning missing data, so we can jump into data modeling directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Define the Data Model\n",
    "#### Conceptual Data Model\n",
    "In this project, I am using fact-dimensional data modeling method. The reason I am using this method is that it will be much more straightforward and easy for users.\n",
    "We will have 1 fact table and 5 dimensional tables.\n",
    "\n",
    "##### Fact table:\n",
    "trainsaction:Loan_Number, Time_Id, Country_Id, Guarantor_Country_Id, Loan_Type, Loan_Status_Id, Amount_Id, End_of_Period, Interest_Rate, Project_ID, Exchange_Adjustment, Borrowers_Obligation, \n",
    "Cancelled_Amount,Undisbursed_Amount, Disbursed_Amount, Repaid_to_IBRD, Due_to_IBRD, Loans_Held\n",
    "\n",
    "##### Dimension table\n",
    "\n",
    "df_time: Time_Id, First_Repayment_Date, Last_Repayment_Date, Board_Approval_Date, Agreement_Signing_Date, Effective_Date_Most_Recent, Closed_Date_Most_Recent\n",
    "\n",
    "df_country: Country_Id, Country_Code, Country, Region\n",
    "\n",
    "df_amount: Amount_Id, Original_Principal_Amount, Sold_3rd_Party, Repaid_3rd_Party, Due_3rd_Party\n",
    "\n",
    "df_loan_type: Loan_Type_Id, Loan_Type\n",
    "\n",
    "df_loan_status: Loan_Status_Id, Loan_Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate time dataframe \n",
    "# By exploring data, we can see that for each loan number, it should only have one set of dates related column. However, we will find for date related columns, it has more than one combination. so I crete this function to find its more frequent value for each loan number. \n",
    "def getss(df, column):\n",
    "    # Create a sql table with loan number and column\n",
    "    df.select('Loan_Number', column).filter('{} is not NULL'.format(column)).filter('{} != \\'None\\''.format(column)).createOrReplaceTempView(\"time\")\n",
    "    # Run query to get the most frequent value of each category for each loan number\n",
    "    x = spark.sql(\"\"\"\n",
    "    SELECT Loan_Number, {} FROM \n",
    "    (\n",
    "    SELECT Loan_Number, {}, count(1) total_records, ROW_NUMBER() OVER (PARTITION BY Loan_Number ORDER BY count(1) desc) AS seqnum\n",
    "    FROM time \n",
    "    group by Loan_Number, {}\n",
    "    )\n",
    "    WHERE seqnum = 1\n",
    "    \"\"\".format(column, column, column))\n",
    "    return x\n",
    "# Getting the most frequent value of each column for each loan number\n",
    "x1 = getss(df, 'First_Repayment_Date')\n",
    "x2 = getss(df, 'Last_Repayment_Date')\n",
    "x3 = getss(df, 'Agreement_Signing_Date')\n",
    "x4 = getss(df, 'Board_Approval_Date')\n",
    "x5 = getss(df, 'Effective_Date_Most_Recent')\n",
    "x6 = getss(df, 'Closed_Date_Most_Recent')\n",
    "# Combine them and drop the duplicate key\n",
    "df_time = x1.join(x2, x1.Loan_Number == x2.Loan_Number).drop(x2.Loan_Number)\n",
    "df_time = df_time.join(x3, df_time.Loan_Number == x3.Loan_Number).drop(x3.Loan_Number)\n",
    "df_time = df_time.join(x4, df_time.Loan_Number == x4.Loan_Number).drop(x4.Loan_Number)\n",
    "df_time = df_time.join(x5, df_time.Loan_Number == x5.Loan_Number).drop(x5.Loan_Number)\n",
    "df_time = df_time.join(x6, df_time.Loan_Number == x6.Loan_Number).drop(x6.Loan_Number)\n",
    "# Add a unique id Time_Id for this dataframe\n",
    "df_time = df_time.withColumn('Time_Id',row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
    "# Rename its column name\n",
    "df_time = df_time.selectExpr('Time_Id', 'Loan_Number', 'First_Repayment_Date as First_Repayment_Date_t', 'Last_Repayment_Date as Last_Repayment_Date_t', 'Agreement_Signing_Date as Agreement_Signing_Date_t','Board_Approval_Date \\\n",
    "                         as Board_Approval_Date_t','Effective_Date_Most_Recent as Effective_Date_Most_Recent_t','Closed_Date_Most_Recent as Closed_Date_Most_Recent_t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate country dataframe \n",
    "df_country = df.select('Country_Code','Country','Region').distinct()\n",
    "newRow = spark.createDataFrame([('GB','United Kingdom','EUROPE AND CENTRAL ASIA')])\n",
    "df_country = df_country.union(newRow)\n",
    "# Add a unique id Country_Id for this dataframe\n",
    "df_country = df_country.withColumn('Country_Id',row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
    "# Casting to the right data type\n",
    "fields = {'Country_Code':'string', 'Country':'string', 'Region':'string', 'Country_Id':'integer'}\n",
    "exprs = [ \"cast ({} as {})\".format(key,value) for key, value in fields.items()]\n",
    "df_country = df_country.selectExpr(*exprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Amount dataframe \n",
    "df_amount = df.select('Loan_Number','Original_Principal_Amount','Sold_3rd_Party','Repaid_3rd_Party', 'Due_3rd_Party').distinct()\n",
    "# Add a unique id Amount_Id for this dataframe\n",
    "df_amount = df_amount.withColumn('Amount_Id',row_number().over(Window.orderBy(monotonically_increasing_id())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Loan_Type dataframe \n",
    "df_loan_type = df.select('Loan_Type').distinct()\n",
    "# Add a unique id Loan_Type_Id for this dataframe\n",
    "df_loan_type = df_loan_type.withColumn('Loan_Type_Id',row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
    "# Casting to the right data type\n",
    "fields = {'Loan_Type':'string', 'Loan_Type_Id':'integer'}\n",
    "exprs = [ \"cast ({} as {})\".format(key,value) for key, value in fields.items()]\n",
    "df_loan_type = df_loan_type.selectExpr(*exprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Loan_Status dataframe \n",
    "df_loan_status = df.select('Loan_Status').distinct()\n",
    "# Add a unique id Loan_Status_Id for this dataframe\n",
    "df_loan_status = df_loan_status.withColumn('Loan_Status_Id',row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
    "# Casting to the right data type\n",
    "fields = {'Loan_Status':'string', 'Loan_Status_Id':'integer'}\n",
    "exprs = [ \"cast ({} as {})\".format(key,value) for key, value in fields.items()]\n",
    "df_loan_status = df_loan_status.selectExpr(*exprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sql tables \n",
    "df_country.createOrReplaceTempView(\"country\")\n",
    "df_time.createOrReplaceTempView(\"time\")\n",
    "df_amount.createOrReplaceTempView(\"amount\")\n",
    "df_loan_type.createOrReplaceTempView(\"loan_type\")\n",
    "df_loan_status.createOrReplaceTempView(\"loan_status\")\n",
    "df.createOrReplaceTempView(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate transaction dataframe by joing log table with the other tables on loan number\n",
    "trainsaction = spark.sql(\"\"\"\n",
    "    select l.Loan_Number, t.Time_Id, c.Country_Id, cc.Country_Id as Guarantor_Country_Id, lt.Loan_Type, ls.Loan_Status_Id, a.Amount_Id,\n",
    "    l.End_of_Period, l.Interest_Rate, l.Project_ID, l.Exchange_Adjustment, l.Borrowers_Obligation, l.Cancelled_Amount,\n",
    "    l.Undisbursed_Amount, l.Disbursed_Amount, l.Repaid_to_IBRD, l.Due_to_IBRD, l.Loans_Held\n",
    "    from log l \n",
    "    join country c on l.Country_Code= c.Country_Code\n",
    "    join country cc on l.Guarantor = cc.Country \n",
    "    join loan_type lt on l.Loan_Type = lt.Loan_Type \n",
    "    join loan_status ls on l.Loan_Status = ls.Loan_Status\n",
    "    join amount a on l.Loan_Number = a.Loan_Number\n",
    "    join time t on l.Loan_Number = t.Loan_Number\n",
    "    \"\"\")\n",
    "# Casting to the right data type\n",
    "fields = {'Loan_Number':'string', 'Time_Id':'integer', 'Country_Id':'integer', 'Guarantor_Country_Id':'integer',\\\n",
    "          'Loan_Type':'string','Loan_Status_Id':'integer', 'Amount_Id':'integer', 'End_of_Period':'timestamp', \\\n",
    "          'Interest_Rate':'float', 'Project_ID':'string', 'Exchange_Adjustment':'float','Borrowers_Obligation':'float',\\\n",
    "          'Cancelled_Amount':'float', 'Undisbursed_Amount':'float', 'Disbursed_Amount':'float','Repaid_to_IBRD':'float', 'Due_to_IBRD':'float', 'Loans_Held':'float'}\n",
    "exprs = [ \"cast ({} as {})\".format(key,value) for key, value in fields.items()]\n",
    "trainsaction = trainsaction.selectExpr(*exprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the loan number column from the dataframes\n",
    "df_amount_final = df_amount.select('Amount_Id','Original_Principal_Amount','Sold_3rd_Party','Repaid_3rd_Party', 'Due_3rd_Party')\n",
    "# Casting to the right data type\n",
    "fields = {'Amount_Id':'integer', 'Original_Principal_Amount':'float', 'Sold_3rd_Party':'float', 'Repaid_3rd_Party':'float', 'Due_3rd_Party':'float'}\n",
    "exprs = [ \"cast ({} as {})\".format(key,value) for key, value in fields.items()]\n",
    "df_amount_final = df_amount_final.selectExpr(*exprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column names\n",
    "df_time_final = df_time.selectExpr('Time_Id', 'First_Repayment_Date_t as First_Repayment_Date', \\\n",
    "                                   'Last_Repayment_Date_t as Last_Repayment_Date','Agreement_Signing_Date_t as Agreement_Signing_Date',\\\n",
    "                                   'Board_Approval_Date_t as Board_Approval_Date','Effective_Date_Most_Recent_t as Effective_Date_Most_Recent',\\\n",
    "                                   'Closed_Date_Most_Recent_t as Closed_Date_Most_Recent')\n",
    "# Casting to the right data type\n",
    "fields = {'Time_Id':'integer', 'First_Repayment_Date':'timestamp', 'Last_Repayment_Date':'timestamp', \\\n",
    "          'Agreement_Signing_Date':'timestamp', 'Board_Approval_Date':'timestamp', 'Effective_Date_Most_Recent':'timestamp', 'Closed_Date_Most_Recent':'timestamp'}\n",
    "exprs = [ \"cast ({} as {})\".format(key,value) for key, value in fields.items()]\n",
    "df_time_final = df_time_final.selectExpr(*exprs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving files to S3 \n",
    "This process will take about 20 minutes. I already saved these files on AWS and you can ignore this part and go to next part directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you want to save data to AWS. The data\n",
    "#start_time = time.time()\n",
    "#df_country.write.csv(\"s3a://udacity-leejohn-w2/loan/country\")\n",
    "#df_time_final.write.csv(\"s3a://udacity-leejohn-w2/loan/time\")\n",
    "#df_loan_status.write.csv(\"s3a://udacity-leejohn-w2/loan/loan_status\")\n",
    "#df_loan_type.write.csv(\"s3a://udacity-leejohn-w2/loan/loan_type\")\n",
    "#df_amount_final.write.csv(\"s3a://udacity-leejohn-w2/loan/amount\")\n",
    "#trainsaction.write.csv(\"s3a://udacity-leejohn/loan-w2/trainsaction\")\n",
    "#print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this command to see the file on AWS\n",
    "s3 = boto3.resource('s3',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                   )\n",
    "## This is to display what we have in S3 \n",
    "sampleDbBucket =  s3.Bucket(\"udacity-leejohn-w2\")\n",
    "i = 0\n",
    "for obj in sampleDbBucket.objects.filter(Prefix=\"loan\"):\n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Run ETL to load the Data\n",
    "First, run below script will create a redshift cluster and it will take about 5-10 min. \n",
    "\n",
    "Second, when you see \"cluster is available\", you can go ahread and run the etl.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script will create a redshift cluster automatically, please don't move forward until you see \"Cluster is available\"\n",
    "%run -i 'Redshift.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All table dropped!\n",
      "All table created!\n",
      "All table loaded!\n"
     ]
    }
   ],
   "source": [
    "# This script will drop, create and load table into redshift cluster. You will see \"All table dropped! All table created! All table loaded!\" if everything works as exptected.\n",
    "%run -i 'etl.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
